---
icon: logos:python
date: 2025-7-31 00:51:00
category:
  - python
title: CNN 和一些概念
---

## CNN 的基本概念

从最基本的线性神经网络到多层感知机（MLP），模型与参数的复杂程度提高了模型的能力。在诸如图像识别等一类的问题中，输入参数一般在百万级别，此时，模型的时空复杂度是无法接受的，我们可以利用卷积神经网络来解决上述问题。

卷积神经网络（Convolutional Neural Network, CNN）是一种深度学习模型，主要用于处理具有类似网格结构的数据，如图像。CNN通过卷积层、池化层和全连接层等结构来自动提取特征，减少参数数量，提高模型的性能。


此外，卷积还有诸多的特性，如**平移不变性**和**局部性**，在图像识别中有诸多优势。

下面，介绍几个关键概念

1. 卷积核与图像卷积
	- 卷积核相当于一个“特征提取”，对图像做卷积，可以将图像中的一些特征信息提取出来。
2. 填充与步幅
	- 卷积核如果不做填充，多次卷积之后会丢失边缘像素，我们可以通过填充卷积之前的原图像，来维持卷积之后图像的大小。
	- 如果存在多个卷积层，会存在参数过大的情况。为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。
3. 输入输出通道
	- 对于输入通道，每个卷积核对每个输入通道进行卷积后，将结果相加，作为一个输出通道。
	- 对于输出通道，每个卷积核处理的结果都单独作为一个通道输出。
	- 若输入为 $(c_{in},w,h)$ 输出可能将为 $(c_{out},w,h)$ .
4. 池化层
	- 与卷积层类似，池化层运算符由一个固定形状的窗口组成。对于卷积层的图像，进行计算汇聚窗口中所有元素的最大值或平均值。因此分为最大汇聚层和平均汇聚层。
	- 最大池化的作用是：**保留最大特征值**，从而避免丢失重要信息，提升模型鲁棒性。
	- 均值池化的作用是：**保留整体特征信息**，通常用于平滑特征图，减少噪声。

通过卷积层、池化层和多层感知机的结合，我们能构建出优秀的深度学习模型。最经典的是用于手写数字识别的 LeNet。

## 模型评估的相关概念

### 混淆矩阵
| 真实 \ 预测  | Positive | Negative |
| ------------ | -------- | -------- |
| **Positive** | **TP**   | **FN**   |
| **Negative** | **FP**   | **TN**   |

### 准确率
$$\rm Accuracy = \dfrac{TP + TN}{TP + TN + FP + FN}$$
预测对的样本占总样本比例
类别均衡且误分类代价相近时使用

### 召回率
$$\rm Recall = \dfrac{TP}{TP + FN}$$
所有真正的正样本中被找出的比例
漏检代价高时使用

### 精确率
$$\rm Precision = \dfrac{TP}{TP + FP}$$
预测为正的样本里真正为正的比例
误报代价高时使用

### F1 分数
准确率与召回率的调和平均
$$\rm F1 = 2 \cdot \dfrac{Precision \cdot Recall}{Precision + Recall}$$

### 损失
是用于衡量**模型预测结果与真实标签之间差异**的指标。

### 损失函数
损失函数根据学习任务的不同有不同的种类。
在深度学习中，结合梯度下降，我们可以合理利用损失函数在深度学习的训练中使模型拟合。

### 验证损失
模型在**验证集**上的损失

## 监督学习和无监督学习

### 监督学习
监督学习中，针对数据，我们给出每组数据的**标签**，通过模型来拟合数据与标签之间的关系。

### 无监督学习

无监督学习中，对于数据，我们不设置**标签**，让模型在学习的过程中学习数据之间的**结构、分布或表示**，典型算法有K-Means和GAN等。
