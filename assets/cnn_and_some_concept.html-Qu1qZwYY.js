import{_ as s}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as n,d as t,o as m}from"./app-DNfKNkgl.js";const l={};function i(p,a){return m(),n("div",null,a[0]||(a[0]=[t('<h2 id="cnn-的基本概念" tabindex="-1"><a class="header-anchor" href="#cnn-的基本概念"><span>CNN 的基本概念</span></a></h2><p>从最基本的线性神经网络到多层感知机（MLP），模型与参数的复杂程度提高了模型的能力。在诸如图像识别等一类的问题中，输入参数一般在百万级别，此时，模型的时空复杂度是无法接受的，我们可以利用卷积神经网络来解决上述问题。</p><p>卷积神经网络（Convolutional Neural Network, CNN）是一种深度学习模型，主要用于处理具有类似网格结构的数据，如图像。CNN通过卷积层、池化层和全连接层等结构来自动提取特征，减少参数数量，提高模型的性能。</p><p>此外，卷积还有诸多的特性，如<strong>平移不变性</strong>和<strong>局部性</strong>，在图像识别中有诸多优势。</p><p>下面，介绍几个关键概念</p><ol><li>卷积核与图像卷积 <ul><li>卷积核相当于一个“特征提取”，对图像做卷积，可以将图像中的一些特征信息提取出来。</li></ul></li><li>填充与步幅 <ul><li>卷积核如果不做填充，多次卷积之后会丢失边缘像素，我们可以通过填充卷积之前的原图像，来维持卷积之后图像的大小。</li><li>如果存在多个卷积层，会存在参数过大的情况。为了高效计算或是缩减采样次数，卷积窗口可以跳过中间位置，每次滑动多个元素。</li></ul></li><li>输入输出通道 <ul><li>对于输入通道，每个卷积核对每个输入通道进行卷积后，将结果相加，作为一个输出通道。</li><li>对于输出通道，每个卷积核处理的结果都单独作为一个通道输出。</li><li>若输入为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>c</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_{in},w,h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">h</span><span class="mclose">)</span></span></span></span> 输出可能将为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>c</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub><mo separator="true">,</mo><mi>w</mi><mo separator="true">,</mo><mi>h</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(c_{out},w,h)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2806em;"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">h</span><span class="mclose">)</span></span></span></span> .</li></ul></li><li>池化层 <ul><li>与卷积层类似，池化层运算符由一个固定形状的窗口组成。对于卷积层的图像，进行计算汇聚窗口中所有元素的最大值或平均值。因此分为最大汇聚层和平均汇聚层。</li><li>最大池化的作用是：<strong>保留最大特征值</strong>，从而避免丢失重要信息，提升模型鲁棒性。</li><li>均值池化的作用是：<strong>保留整体特征信息</strong>，通常用于平滑特征图，减少噪声。</li></ul></li></ol><p>通过卷积层、池化层和多层感知机的结合，我们能构建出优秀的深度学习模型。最经典的是用于手写数字识别的 LeNet。</p><h2 id="模型评估的相关概念" tabindex="-1"><a class="header-anchor" href="#模型评估的相关概念"><span>模型评估的相关概念</span></a></h2><h3 id="混淆矩阵" tabindex="-1"><a class="header-anchor" href="#混淆矩阵"><span>混淆矩阵</span></a></h3><table><thead><tr><th>真实 \\ 预测</th><th>Positive</th><th>Negative</th></tr></thead><tbody><tr><td><strong>Positive</strong></td><td><strong>TP</strong></td><td><strong>FN</strong></td></tr><tr><td><strong>Negative</strong></td><td><strong>FP</strong></td><td><strong>TN</strong></td></tr></tbody></table><h3 id="准确率" tabindex="-1"><a class="header-anchor" href="#准确率"><span>准确率</span></a></h3><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">A</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">y</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">P</mi><mo>+</mo><mi mathvariant="normal">T</mi><mi mathvariant="normal">N</mi></mrow><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">P</mi><mo>+</mo><mi mathvariant="normal">T</mi><mi mathvariant="normal">N</mi><mo>+</mo><mi mathvariant="normal">F</mi><mi mathvariant="normal">P</mi><mo>+</mo><mi mathvariant="normal">F</mi><mi mathvariant="normal">N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\\rm Accuracy = \\dfrac{TP + TN}{TP + TN + FP + FN} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mord mathrm" style="margin-right:0.01389em;">Accuracy</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">TP</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">TN</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">FP</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">FN</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">TP</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">TN</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p><p>预测对的样本占总样本比例<br> 类别均衡且误分类代价相近时使用</p><h3 id="召回率" tabindex="-1"><a class="header-anchor" href="#召回率"><span>召回率</span></a></h3><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">P</mi></mrow><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">P</mi><mo>+</mo><mi mathvariant="normal">F</mi><mi mathvariant="normal">N</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\\rm Recall = \\dfrac{TP}{TP + FN} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mord mathrm">Recall</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">TP</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">FN</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">TP</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p><p>所有真正的正样本中被找出的比例<br> 漏检代价高时使用</p><h3 id="精确率" tabindex="-1"><a class="header-anchor" href="#精确率"><span>精确率</span></a></h3><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mo>=</mo><mfrac><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">P</mi></mrow><mrow><mi mathvariant="normal">T</mi><mi mathvariant="normal">P</mi><mo>+</mo><mi mathvariant="normal">F</mi><mi mathvariant="normal">P</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\\rm Precision = \\dfrac{TP}{TP + FP} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1297em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mord mathrm">Precision</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3603em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">TP</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">FP</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">TP</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p><p>预测为正的样本里真正为正的比例<br> 误报代价高时使用</p><h3 id="f1-分数" tabindex="-1"><a class="header-anchor" href="#f1-分数"><span>F1 分数</span></a></h3><p>准确率与召回率的调和平均</p><p class="katex-block"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="normal">F</mi><mn>1</mn><mo>=</mo><mn>2</mn><mo>⋅</mo><mfrac><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mo>⋅</mo><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mo>+</mo><mi mathvariant="normal">R</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">l</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\\rm F1 = 2 \\cdot \\dfrac{Precision \\cdot Recall}{Precision + Recall} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1408em;vertical-align:-0.7693em;"></span><span class="mord"><span class="mord mathrm">F1</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em;"></span><span class="mord mathrm">2</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">Precision</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">Recall</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathrm">Precision</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em;"></span><span class="mord mathrm">Recall</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></span></p><h3 id="损失" tabindex="-1"><a class="header-anchor" href="#损失"><span>损失</span></a></h3><p>是用于衡量<strong>模型预测结果与真实标签之间差异</strong>的指标。</p><h3 id="损失函数" tabindex="-1"><a class="header-anchor" href="#损失函数"><span>损失函数</span></a></h3><p>损失函数根据学习任务的不同有不同的种类。<br> 在深度学习中，结合梯度下降，我们可以合理利用损失函数在深度学习的训练中使模型拟合。</p><h3 id="验证损失" tabindex="-1"><a class="header-anchor" href="#验证损失"><span>验证损失</span></a></h3><p>模型在<strong>验证集</strong>上的损失</p><h2 id="监督学习和无监督学习" tabindex="-1"><a class="header-anchor" href="#监督学习和无监督学习"><span>监督学习和无监督学习</span></a></h2><h3 id="监督学习" tabindex="-1"><a class="header-anchor" href="#监督学习"><span>监督学习</span></a></h3><p>监督学习中，针对数据，我们给出每组数据的<strong>标签</strong>，通过模型来拟合数据与标签之间的关系。</p><h3 id="无监督学习" tabindex="-1"><a class="header-anchor" href="#无监督学习"><span>无监督学习</span></a></h3><p>无监督学习中，对于数据，我们不设置<strong>标签</strong>，让模型在学习的过程中学习数据之间的<strong>结构、分布或表示</strong>，典型算法有K-Means和GAN等。</p>',33)]))}const o=s(l,[["render",i],["__file","cnn_and_some_concept.html.vue"]]),c=JSON.parse('{"path":"/posts/Python/cnn_and_some_concept.html","title":"CNN 和一些概念","lang":"zh-CN","frontmatter":{"icon":"logos:python","date":"2025-07-31T00:51:00.000Z","category":["python"],"title":"CNN 和一些概念","description":"CNN 的基本概念 从最基本的线性神经网络到多层感知机（MLP），模型与参数的复杂程度提高了模型的能力。在诸如图像识别等一类的问题中，输入参数一般在百万级别，此时，模型的时空复杂度是无法接受的，我们可以利用卷积神经网络来解决上述问题。 卷积神经网络（Convolutional Neural Network, CNN）是一种深度学习模型，主要用于处理具有...","head":[["meta",{"property":"og:url","content":"https://chenwenda316.github.io/posts/Python/cnn_and_some_concept.html"}],["meta",{"property":"og:site_name","content":"for_each"}],["meta",{"property":"og:title","content":"CNN 和一些概念"}],["meta",{"property":"og:description","content":"CNN 的基本概念 从最基本的线性神经网络到多层感知机（MLP），模型与参数的复杂程度提高了模型的能力。在诸如图像识别等一类的问题中，输入参数一般在百万级别，此时，模型的时空复杂度是无法接受的，我们可以利用卷积神经网络来解决上述问题。 卷积神经网络（Convolutional Neural Network, CNN）是一种深度学习模型，主要用于处理具有..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-07-30T16:55:44.000Z"}],["meta",{"property":"article:published_time","content":"2025-07-31T00:51:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-07-30T16:55:44.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"CNN 和一些概念\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2025-07-31T00:51:00.000Z\\",\\"dateModified\\":\\"2025-07-30T16:55:44.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"for-each\\",\\"url\\":\\"https://for-each.cn\\"}]}"]]},"headers":[{"level":2,"title":"CNN 的基本概念","slug":"cnn-的基本概念","link":"#cnn-的基本概念","children":[]},{"level":2,"title":"模型评估的相关概念","slug":"模型评估的相关概念","link":"#模型评估的相关概念","children":[{"level":3,"title":"混淆矩阵","slug":"混淆矩阵","link":"#混淆矩阵","children":[]},{"level":3,"title":"准确率","slug":"准确率","link":"#准确率","children":[]},{"level":3,"title":"召回率","slug":"召回率","link":"#召回率","children":[]},{"level":3,"title":"精确率","slug":"精确率","link":"#精确率","children":[]},{"level":3,"title":"F1 分数","slug":"f1-分数","link":"#f1-分数","children":[]},{"level":3,"title":"损失","slug":"损失","link":"#损失","children":[]},{"level":3,"title":"损失函数","slug":"损失函数","link":"#损失函数","children":[]},{"level":3,"title":"验证损失","slug":"验证损失","link":"#验证损失","children":[]}]},{"level":2,"title":"监督学习和无监督学习","slug":"监督学习和无监督学习","link":"#监督学习和无监督学习","children":[{"level":3,"title":"监督学习","slug":"监督学习","link":"#监督学习","children":[]},{"level":3,"title":"无监督学习","slug":"无监督学习","link":"#无监督学习","children":[]}]}],"git":{"createdTime":1753894544000,"updatedTime":1753894544000,"contributors":[{"name":"for_each316","username":"for_each316","email":"2014214637@qq.com","commits":1,"url":"https://github.com/for_each316"}]},"readingTime":{"minutes":3.4,"words":1021},"filePathRelative":"posts/Python/cnn_and_some_concept.md","localizedDate":"2025年7月31日","excerpt":"<h2>CNN 的基本概念</h2>\\n<p>从最基本的线性神经网络到多层感知机（MLP），模型与参数的复杂程度提高了模型的能力。在诸如图像识别等一类的问题中，输入参数一般在百万级别，此时，模型的时空复杂度是无法接受的，我们可以利用卷积神经网络来解决上述问题。</p>\\n<p>卷积神经网络（Convolutional Neural Network, CNN）是一种深度学习模型，主要用于处理具有类似网格结构的数据，如图像。CNN通过卷积层、池化层和全连接层等结构来自动提取特征，减少参数数量，提高模型的性能。</p>\\n<p>此外，卷积还有诸多的特性，如<strong>平移不变性</strong>和<strong>局部性</strong>，在图像识别中有诸多优势。</p>","autoDesc":true}');export{o as comp,c as data};
